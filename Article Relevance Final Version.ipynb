{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from bert_embedding import BertEmbedding\n",
    "from operator import itemgetter\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    # Convert the input text into lowercase text\n",
    "    return np.char.lower(str(data))\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    # Tokenize the input text and remove stopwords from the corpus\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 3:\n",
    "            new_text = new_text + \" \" + lemmatizer.lemmatize(w)\n",
    "    return new_text\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    # Remove punctuations defined below from input text\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    # Remove apostrophe from the input text\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def convert_numbers(data):\n",
    "    # Convert numbers to text form in input text\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "\n",
    "def get_bigrams(text):\n",
    "    \n",
    "    \"\"\"Input\n",
    "    ----------\n",
    "    text : str or list of strings\n",
    "    n    : number of word in each combination string ie if n = 2 the tokenization will happen in two word pairs\n",
    "    \n",
    "    Output\n",
    "    -------\n",
    "    tokens : The output would be a list of lists and each element list of the list will contain\n",
    "             unigram and n_gram tokens. This functions can be modified for a range of grams but right now\n",
    "             it will be best to use it with n = 2.\n",
    "    \"\"\"\n",
    "    bi_grams = ngrams(word_tokenize(text), 2)\n",
    "    unigrams = word_tokenize(text)\n",
    "    bigrams = [' '.join(grams) for grams in bi_grams]\n",
    "    tokens = unigrams + bigrams\n",
    "    return tokens\n",
    "\n",
    "def preprocess(data):\n",
    "    # Preprocess the input text\n",
    "    data = convert_lower_case(data)\n",
    "    #data = remove_punctuation(data) #remove comma seperately\n",
    "    #data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    #data = convert_numbers(data)\n",
    "    #data = remove_punctuation(data)\n",
    "    #data = convert_numbers(data)\n",
    "    #data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    #data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(dataframe, column):\n",
    "    tokens = []\n",
    "    for i in dataframe[column]:\n",
    "        tokens.append(get_bigrams(preprocess(str(i))))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-918a2153c0c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word2vec-google-news-300'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# loading the Word2Vec pretrained embeddings (size = 1.6 GB)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\downloader.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/gensim-data\\word2vec-google-news-300\\__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'word2vec-google-news-300'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"word2vec-google-news-300.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    384\u001b[0m                     \u001b[1;31m# TODO use frombuffer or something similar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                 \u001b[0madd_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36madd_word\u001b[1;34m(word, weights)\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vocabulary file is incomplete: '%s' is missing\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-google-news-300') # loading the Word2Vec pretrained embeddings (size = 1.6 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    # get a list of all the synonyms of the input word\n",
    "    word = wordnet.synsets(word)\n",
    "    syns = [w.lemma_names() for w in word]\n",
    "    synonyms = []\n",
    "    for i in syns:\n",
    "        for j in i:\n",
    "            synonyms.append(j)\n",
    "    synonyms = unique(synonyms)\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Structural performance of non-plastered modula...</td>\n",
       "      <td>Straw bale construction has a proven track rec...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Effects of roll and flail conditioning systems...</td>\n",
       "      <td>Miscanthus and switchgrass have been identifie...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Effectiveness of straw bale check dams at redu...</td>\n",
       "      <td>Post-fire flooding and elevated sediment loads...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Construction and monitoring of experimental st...</td>\n",
       "      <td>Straw bale buildings have the potential reduce...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A review of densified solid biomass for energy...</td>\n",
       "      <td>Growing concerns over the environmental impact...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37927</td>\n",
       "      <td>Glossary</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37928</td>\n",
       "      <td>Glossary</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37929</td>\n",
       "      <td>e-Glossary</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37930</td>\n",
       "      <td>Glossary</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37931</td>\n",
       "      <td>Glossary</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37932 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0      Structural performance of non-plastered modula...   \n",
       "1      Effects of roll and flail conditioning systems...   \n",
       "2      Effectiveness of straw bale check dams at redu...   \n",
       "3      Construction and monitoring of experimental st...   \n",
       "4      A review of densified solid biomass for energy...   \n",
       "...                                                  ...   \n",
       "37927                                           Glossary   \n",
       "37928                                           Glossary   \n",
       "37929                                         e-Glossary   \n",
       "37930                                           Glossary   \n",
       "37931                                           Glossary   \n",
       "\n",
       "                                                Abstract  \\\n",
       "0      Straw bale construction has a proven track rec...   \n",
       "1      Miscanthus and switchgrass have been identifie...   \n",
       "2      Post-fire flooding and elevated sediment loads...   \n",
       "3      Straw bale buildings have the potential reduce...   \n",
       "4      Growing concerns over the environmental impact...   \n",
       "...                                                  ...   \n",
       "37927                                                      \n",
       "37928                                                      \n",
       "37929                                                      \n",
       "37930                                                      \n",
       "37931                                                      \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.sciencedirect.com/science/article/...  \n",
       "1      https://www.sciencedirect.com/science/article/...  \n",
       "2      https://www.sciencedirect.com/science/article/...  \n",
       "3      https://www.sciencedirect.com/science/article/...  \n",
       "4      https://www.sciencedirect.com/science/article/...  \n",
       "...                                                  ...  \n",
       "37927  https://www.sciencedirect.com/science/article/...  \n",
       "37928  https://www.sciencedirect.com/science/article/...  \n",
       "37929  https://www.sciencedirect.com/science/article/...  \n",
       "37930  https://www.sciencedirect.com/science/article/...  \n",
       "37931  https://www.sciencedirect.com/science/article/...  \n",
       "\n",
       "[37932 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title = []\n",
    "Abstract = []\n",
    "Url = []\n",
    "\n",
    "path = 'C://Users//HP//Desktop//Articles//'\n",
    "file_name = '_Article.json'\n",
    "\n",
    "for i in range(1, 11):\n",
    "    with open(path+str(i)+file_name, encoding=\"utf8\") as json_file:\n",
    "        temp_data = json.load(json_file)\n",
    "        for j in temp_data:\n",
    "            temp_title = j['Title']\n",
    "            temp_abstract = j['Abstract']\n",
    "            temp_url = j['Url']\n",
    "            Title.append(temp_title)\n",
    "            Abstract.append(temp_abstract)\n",
    "            Url.append(temp_url)\n",
    "            \n",
    "df = pd.DataFrame()\n",
    "df['Title'] = Title\n",
    "df['Abstract'] = Abstract\n",
    "df['Url'] = Url\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_scores(abstract, title):\n",
    "    \n",
    "    \"\"\"given body and titles of the articles this funtion calculates the tfidf scores of the words in the text corpus.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       title        : Titles of the articles\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\n",
    "       \"\"\"\n",
    "   \n",
    "    \n",
    "    N = len(abstract)\n",
    "    DF = {}\n",
    "\n",
    "    for i in range(N):\n",
    "        tokens = abstract[i]\n",
    "        for w in tokens:\n",
    "            try:\n",
    "                DF[w].add(i)\n",
    "            except:\n",
    "                DF[w] = {i}\n",
    "    for i in DF:\n",
    "        DF[i] = len(DF[i])\n",
    "    \n",
    "    total_vocab = [x for x in DF]\n",
    "\n",
    "    doc = 0\n",
    "\n",
    "    tf_idf = {}\n",
    "\n",
    "    for i in range(N):\n",
    "    \n",
    "        tokens = abstract[i]\n",
    "    \n",
    "        counter = Counter(tokens + title[i])\n",
    "        words_count = len(tokens + title[i])\n",
    "    \n",
    "        for token in np.unique(tokens):\n",
    "        \n",
    "            tf = counter[token]/words_count\n",
    "            df = doc_freq(token)\n",
    "            idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "            tf_idf[doc, token] = tf*idf\n",
    "\n",
    "        doc += 1\n",
    "    return tf_idf\n",
    "\n",
    "\n",
    "\n",
    "def tfidf_abstract_scores(abstract):\n",
    "    \n",
    "    \"\"\"given body articles this funtion calculates the tfidf scores of the words in the text corpus.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       \n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\n",
    "       \"\"\"\n",
    "    \n",
    "    \n",
    "    N = len(abstract)\n",
    "    DF = {}\n",
    "\n",
    "    for i in range(N):\n",
    "        tokens = abstract[i]\n",
    "        for w in tokens:\n",
    "            try:\n",
    "                DF[w].add(i)\n",
    "            except:\n",
    "                DF[w] = {i}\n",
    "    for i in DF:\n",
    "        DF[i] = len(DF[i])\n",
    "    \n",
    "    total_vocab = [x for x in DF]\n",
    "\n",
    "    doc = 0\n",
    "\n",
    "    tf_idf = {}\n",
    "\n",
    "    for i in range(N):\n",
    "    \n",
    "        tokens = abstract[i]\n",
    "    \n",
    "        counter = Counter(tokens)\n",
    "        words_count = len(tokens)\n",
    "    \n",
    "        for token in np.unique(tokens):\n",
    "        \n",
    "            tf = counter[token]/words_count\n",
    "            df = doc_freq(token)\n",
    "            idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "            tf_idf[doc, token] = tf*idf\n",
    "\n",
    "        doc += 1\n",
    "    return tf_idf\n",
    "\n",
    "\n",
    "def tfidf_title_scores(title):\n",
    "    \n",
    "    \"\"\"given body articles this funtion calculates the tfidf scores of the words in the text corpus.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       \n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\n",
    "       \"\"\"\n",
    "    N = len(title)\n",
    "    DF = {}\n",
    "\n",
    "    for i in range(N):\n",
    "        tokens = title[i]\n",
    "        for w in tokens:\n",
    "            try:\n",
    "                DF[w].add(i)\n",
    "            except:\n",
    "                DF[w] = {i}\n",
    "    for i in DF:\n",
    "        DF[i] = len(DF[i])\n",
    "    \n",
    "    total_vocab = [x for x in DF]\n",
    "\n",
    "    doc = 0\n",
    "\n",
    "    tf_idf = {}\n",
    "\n",
    "    for i in range(N):\n",
    "    \n",
    "        tokens = title[i]\n",
    "    \n",
    "        counter = Counter(tokens)\n",
    "        words_count = len(tokens)\n",
    "    \n",
    "        for token in np.unique(tokens):\n",
    "        \n",
    "            tf = counter[token]/words_count\n",
    "            df = doc_freq(token)\n",
    "            idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "            tf_idf[doc, token] = tf*idf\n",
    "\n",
    "        doc += 1\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_title_filter(query, title, k):\n",
    "    \"\"\"given the query, body of articles, titles of articles, k (output articles threshold) and tfifd_method\n",
    "      this funtion extract k number of articles that are most relevent to the query keywords.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       title        : Titles of the articles\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\"\"\"\n",
    "    tokens = query\n",
    "    \n",
    "\n",
    "    tf_idf = tfidf_title_scores(title)\n",
    "    \n",
    "    relevent_indices = []\n",
    "    \n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)    \n",
    "    \n",
    "    for i in query_weights[:k]:\n",
    "        relevent_indices.append(i[0])\n",
    "        \n",
    "    return relevent_indices\n",
    "\n",
    "def tfidf_abstract_filter(query, abstract, k):\n",
    "    \"\"\"given the query, body of articles, titles of articles, k (output articles threshold) and tfifd_method\n",
    "      this funtion extract k number of articles that are most relevent to the query keywords.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       title        : Titles of the articles\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\"\"\"\n",
    "    tokens = query\n",
    "    \n",
    "    tf_idf = tfidf_abstract_scores(abstract)\n",
    "    \n",
    "    relevent_indices = []\n",
    "    \n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)    \n",
    "    \n",
    "    for i in query_weights[:k]:\n",
    "        relevent_indices.append(i[0])\n",
    "        \n",
    "    return relevent_indices\n",
    "\n",
    "\n",
    "def tfidf_abstract_title_filter(query, abstract, title,  k):\n",
    "    \"\"\"given the query, body of articles, titles of articles, k (output articles threshold) and tfifd_method\n",
    "      this funtion extract k number of articles that are most relevent to the query keywords.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       body         : Body or abstracts of the articles.\n",
    "       title        : Titles of the articles\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       tf_idf       : A dictionary of tf_idf scorese of the vocabulary.\"\"\"\n",
    "    tokens = query\n",
    "    \n",
    "    tf_idf = tfidf_scores(abstract, title)\n",
    "    \n",
    "    relevent_indices = []\n",
    "    \n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)    \n",
    "    \n",
    "    for i in query_weights[:k]:\n",
    "        relevent_indices.append(i[0])\n",
    "        \n",
    "    return relevent_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_Mover_Distance(query, docs, k):\n",
    "    \n",
    "    \"\"\"given a query, corpus of text, a list of indices, and k, this functions outputs a list of indices\n",
    "       of the documents that are most similar to the query based on the context captured by context captured by\n",
    "       Word2vec pretrained embeddings \"Google-news-300\" It’s 1.5GB! It includes word vectors for a vocabulary\n",
    "       of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset.\n",
    "       The vector length is 300 features. This function use Word Mover Distance to calculate the similarity\n",
    "       between documents and given query.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       query          : A string of words.\n",
    "       docs           : Text corpus, a list of lists with tokenized sentences.\n",
    "       indices        : A list of indices.\n",
    "       k              : Number of outputs.\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       sorted_indices : A list of k number of indices belong the documents that are most relevent to query.\n",
    "       \"\"\"\n",
    "    \n",
    "    relevent_docs = []\n",
    "    for i in range(len(docs)):\n",
    "        relevent_docs.append(docs[i])\n",
    "        \n",
    "    distance = []\n",
    "    for doc in relevent_docs:\n",
    "        distance.append(model.wmdistance(doc, query))\n",
    "    \n",
    "    docs_distance = []\n",
    "    for i in range(len(docs)):\n",
    "        docs_distance.append([distance[i], i])\n",
    "    \n",
    "    sorted_docs_distance = sorted(docs_distance, key=itemgetter(0), reverse = False)\n",
    "    sorted_indices = []\n",
    "    for i in sorted_docs_distance[:k]:\n",
    "        sorted_indices.append(i[1])\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_filter_regional(dataframe, column):\n",
    "    '''Given data frame and column of the data frame this function outputs the indices of articles that do not have\n",
    "        the name of any goepolical entity in it.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       dataframe    : A pandas data frame.\n",
    "       column       : Specific column of the data frame.\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       indices      : A list of indices of articles that does not have have any geoplolictacl entity in them.'''\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    indices = []\n",
    "    doc_ents = []\n",
    "    for i in range(len(dataframe[column])):\n",
    "        document = dataframe.loc[i, column]\n",
    "        document = remove_stop_words(document)\n",
    "        document = word_tokenize(document)\n",
    "        _doc_ents = []\n",
    "        for word in document:\n",
    "            word = nlp(word)\n",
    "            for entity in word.ents:\n",
    "                _doc_ents.append(entity.label_)\n",
    "        doc_ents.append(_doc_ents)\n",
    "\n",
    "    for i in range(len(dataframe[column])):\n",
    "        doc = doc_ents[i]\n",
    "        if 'GPE' not in doc:\n",
    "            indices.append(i)\n",
    "            \n",
    "        else:\n",
    "            print('Aritcle', i, 'has a Geopolitical Entity in it')\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_filter_historical(dataframe, column):\n",
    "    \n",
    "    \"\"\"Given data frame and column of the data frame this function outputs the indices of articles that do not have\n",
    "        the both the date and comparision words in it.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       dataframe    : A pandas data frame.\n",
    "       column       : Specific column of the data frame.\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       indices      : A list of indices of articles that does not have both the date and comparision word in them.\n",
    "       \"\"\"\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    indices = []\n",
    "    doc_ents = []\n",
    "    for i in range(len(dataframe[column])):\n",
    "        document = dataframe.loc[i, column]\n",
    "        document = remove_stop_words(document)\n",
    "        document = word_tokenize(document)\n",
    "        _doc_ents = []\n",
    "        for word in document:\n",
    "            word = nlp(word)\n",
    "            for entity in word.ents:\n",
    "                _doc_ents.append(entity.label_)\n",
    "        doc_ents.append(_doc_ents)\n",
    "\n",
    "    for i in range(len(dataframe[column])):\n",
    "        doc = doc_ents[i]\n",
    "        comperision = ['from', 'since', 'versus', 'vs', 'between']\n",
    "        if 'DATE' in doc:\n",
    "            document = dataframe.loc[i, column]\n",
    "            document = word_tokenize(document)\n",
    "            for token in document:\n",
    "                if token in comperision:\n",
    "                    print('Aritcle', i, 'has a date and a comperision word')\n",
    "        else:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_filter(query, dataframe, col_name, top_k,similarity_method):\n",
    "    \n",
    "    \"\"\"given query, dataframe, column name or top k numbers of output and similarity method as input this \n",
    "       function extract articles that are most relevent to the query keywords by using tfidf model and then\n",
    "       sort these relevent articles based on contextual similarity by any of 4 state of the art methods for\n",
    "       semantic similarity of text. Finaly it outputs a data frame that contains the title, abstract and url\n",
    "       of the relevent article.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       query          : A string of words(keywords to match the articles).\n",
    "       dataframe      : A pandas data frame.\n",
    "       col_name       : Input either 'Abstract' or 'Title' 'Abstract+Title' for ranking.\n",
    "       top_k          : Number of filtered articles.\n",
    "       method         : One of four otiopns for semantic similarity 'cosine_similarity', 'universal_encoder_inner',\n",
    "                        'universal_encoder_cosine' and 'word_mover_distance'.\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       indices        : A list of indices that belong to k number of most relavent documents.\n",
    "       \"\"\"\n",
    "    \n",
    "    if col_name == 'Abstract':\n",
    "        docs = get_tokens(dataframe, col_name)\n",
    "        if similarity_method == 'tfidf':\n",
    "            final_indices = tfidf_abstract_filter(query, docs,  top_k)\n",
    "        elif similarity_method == 'word_mover_distance':\n",
    "            final_indices = Word_Mover_Distance(query, docs, top_k)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif col_name == 'Title':\n",
    "        docs = get_tokens(dataframe, col_name)\n",
    "        if similarity_method == 'tfidf':\n",
    "            final_indices = tfidf_title_filter(query, docs, top_k)\n",
    "        elif similarity_method == 'word_mover_distance':\n",
    "            final_indices = Word_Mover_Distance(query, docs, top_k)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif col_name == 'Abstract+Title':\n",
    "        abstract = get_tokens(dataframe, 'Abstract')\n",
    "        title = get_tokens(dataframe, 'Title')\n",
    "        if similarity_method == 'tfidf':\n",
    "            final_indices = tfidf_abstract_title_filter(query, abstract, title, top_k)\n",
    "        elif similarity_method == 'word_mover_distance':\n",
    "            final_indices = Word_Mover_Distance(query, abstract, top_k)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return final_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_filter(query, query_method, dataframe, filter_type, col_name, top_k, similarity_method):\n",
    "    \n",
    "    \n",
    "    \"\"\"given query, query method, dataframe, filter_type, column name or top k numbers of outputs and similarity\n",
    "       method as input this function extract articles that are most relevent to the query keywords by using tfidf\n",
    "       model and then sort these relevent articles based on contextual similarity by any of 4 state of the art methods for\n",
    "       semantic similarity of text. Finaly it outputs a data frame that contains the title, abstract and url\n",
    "       of the relevent article.\n",
    "       \n",
    "       Input\n",
    "       -------\n",
    "       query          : A string of words(keywords to match the articles).\n",
    "       query_method   : Method of query either normal 'query' or 'scope'\n",
    "       dataframe      : A pandas data frame.\n",
    "       filter_type    : Chose from options \"Keywords\", \"Historical\", \"Regional\"\n",
    "       col_name       : Input either 'Abstract' or 'Title' 'Abstract+Title' for ranking.\n",
    "       top_k          : Number of filtered articles.\n",
    "       method         : One of four otiopns for semantic similarity 'cosine_similarity', 'universal_encoder_inner',\n",
    "                        'universal_encoder_cosine' and 'word_mover_distance'.\n",
    "       \n",
    "       Output\n",
    "       -------\n",
    "       indices        : A list of indices that belong to k number of most relavent documents.\n",
    "       \"\"\"\n",
    "\n",
    "    \n",
    "    if query_method == 'query':\n",
    "        query = get_bigrams(preprocess(query))\n",
    "    elif query_method == 'scope':\n",
    "        query = get_synonyms(query)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if filter_type == 'Keywords':\n",
    "        final_indices = keywords_filter(query, dataframe, col_name, top_k, similarity_method)\n",
    "        \n",
    "    elif filter_type == 'Regional':\n",
    "        if col_name == 'Title':\n",
    "            col_name = col_name\n",
    "        elif col_name == 'Abstract':\n",
    "            col_name = col_name\n",
    "        elif col_name == 'Abstract+Title':\n",
    "            col_name = 'Abstract'\n",
    "        else:\n",
    "            pass\n",
    "        final_indices = nlp_filter_regional(dataframe, col_name)\n",
    "        \n",
    "    elif filter_type == 'Historical':\n",
    "        if col_name == 'Title':\n",
    "            col_name = col_name\n",
    "        elif col_name == 'Abstract':\n",
    "            col_name = col_name\n",
    "        elif col_name == 'Abstract+Title':\n",
    "            col_name = 'Abstract'\n",
    "        else:\n",
    "            pass\n",
    "        final_indices = nlp_filter_historical(dataframe, col_name)\n",
    "    else:\n",
    "        pass\n",
    "    return final_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - query_method  'scope':\n",
    "\n",
    "If the user select the query_method 'scope' the user can input a single word as query, the query would then be converted into a list of synonyms and used as query in the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('aqua', 'scope', df, 'Keywords', 'Abstract', 10, 'word_mover_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Before the beginning</td>\n",
       "      <td>The very first living thing is still alive ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Traitement conventionnel du myélome multiple</td>\n",
       "      <td>Environ 50% des patients atteints de myélome m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dissolution behavior of silk fibroin in a low ...</td>\n",
       "      <td>Regenerated Silk biomaterials are usually pre-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Chapter 12: Olea europaea as Potential Source ...</td>\n",
       "      <td>The olive tree (Olea europaea L.) belongs to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Chapter 12: Olea europaea as Potential Source ...</td>\n",
       "      <td>The olive tree (Olea europaea L.) belongs to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Water hyacinths as a resource in agriculture a...</td>\n",
       "      <td>Water hyacinths are becoming a problem in lake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Chapter 32: City of San Francisco, California,...</td>\n",
       "      <td>Located on a peninsula in northern California ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Designing for Workspace Safety</td>\n",
       "      <td>Abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Chapter 3: Wastewater remediation via combo-te...</td>\n",
       "      <td>Abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Exploiting microbubble-microbe synergy for bio...</td>\n",
       "      <td>Abstract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                               Before the beginning   \n",
       "1       Traitement conventionnel du myélome multiple   \n",
       "2  Dissolution behavior of silk fibroin in a low ...   \n",
       "3  Chapter 12: Olea europaea as Potential Source ...   \n",
       "4  Chapter 12: Olea europaea as Potential Source ...   \n",
       "5  Water hyacinths as a resource in agriculture a...   \n",
       "6  Chapter 32: City of San Francisco, California,...   \n",
       "7                     Designing for Workspace Safety   \n",
       "8  Chapter 3: Wastewater remediation via combo-te...   \n",
       "9  Exploiting microbubble-microbe synergy for bio...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  The very first living thing is still alive ins...  \n",
       "1  Environ 50% des patients atteints de myélome m...  \n",
       "2  Regenerated Silk biomaterials are usually pre-...  \n",
       "3  The olive tree (Olea europaea L.) belongs to t...  \n",
       "4  The olive tree (Olea europaea L.) belongs to t...  \n",
       "5  Water hyacinths are becoming a problem in lake...  \n",
       "6  Located on a peninsula in northern California ...  \n",
       "7                                           Abstract  \n",
       "8                                           Abstract  \n",
       "9                                           Abstract  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - query_method  'query':\n",
    "\n",
    "If the user select query_method as 'query' the user can input multiple words as query, these words would then be converted into a list of unigram and bigram tokens and used in the algorithm to extract relevent articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('climate change', 'query', df, 'Keywords', 'Abstract', 10, 'word_mover_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 13: Climate Change and Agricultural Sy...</td>\n",
       "      <td>In this chapter we outline the two-way links b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Chapter 21: Cyanobacterial Bioenergy and Biofu...</td>\n",
       "      <td>In recent decades, there have been significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Variation in annual carbon fluxes affecting th...</td>\n",
       "      <td>Estimation of soil-related carbon (C) fluxes i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Chemicals From Renewable Sources</td>\n",
       "      <td>Increasing concerns on climate change and ener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Plants in a warmer world</td>\n",
       "      <td>Climate is a major determinant for the phenolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>A review of climate change, mitigation and ada...</td>\n",
       "      <td>Global climate change is a change in the long-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Chapter Two: Global Warming and Its Possible I...</td>\n",
       "      <td>Progress has been significant in climate scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Chapter Two: Global Warming and Its Possible I...</td>\n",
       "      <td>Progress has been significant in climate scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Modeling of Thermochemical Conversion of Bioma...</td>\n",
       "      <td>The growth in the world energy demand, as well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Decadal analysis of impact of future climate o...</td>\n",
       "      <td>Different aspects of climate change, such as i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Chapter 13: Climate Change and Agricultural Sy...   \n",
       "1  Chapter 21: Cyanobacterial Bioenergy and Biofu...   \n",
       "2  Variation in annual carbon fluxes affecting th...   \n",
       "3                   Chemicals From Renewable Sources   \n",
       "4                           Plants in a warmer world   \n",
       "5  A review of climate change, mitigation and ada...   \n",
       "6  Chapter Two: Global Warming and Its Possible I...   \n",
       "7  Chapter Two: Global Warming and Its Possible I...   \n",
       "8  Modeling of Thermochemical Conversion of Bioma...   \n",
       "9  Decadal analysis of impact of future climate o...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  In this chapter we outline the two-way links b...  \n",
       "1  In recent decades, there have been significant...  \n",
       "2  Estimation of soil-related carbon (C) fluxes i...  \n",
       "3  Increasing concerns on climate change and ener...  \n",
       "4  Climate is a major determinant for the phenolo...  \n",
       "5  Global climate change is a change in the long-...  \n",
       "6  Progress has been significant in climate scien...  \n",
       "7  Progress has been significant in climate scien...  \n",
       "8  The growth in the world energy demand, as well...  \n",
       "9  Different aspects of climate change, such as i...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Filter Type 'Historical':\n",
    "\n",
    "If user want to filter out all the articles that have historical comperision in them he/she can type 'Historical' in filter_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritcle 2 has a date and a comperision word\n",
      "Aritcle 2 has a date and a comperision word\n",
      "Aritcle 4 has a date and a comperision word\n",
      "Aritcle 4 has a date and a comperision word\n",
      "Aritcle 6 has a date and a comperision word\n",
      "Aritcle 7 has a date and a comperision word\n",
      "Aritcle 13 has a date and a comperision word\n",
      "Aritcle 19 has a date and a comperision word\n",
      "Aritcle 19 has a date and a comperision word\n",
      "Aritcle 19 has a date and a comperision word\n",
      "Aritcle 28 has a date and a comperision word\n",
      "Aritcle 33 has a date and a comperision word\n",
      "Aritcle 33 has a date and a comperision word\n",
      "Aritcle 33 has a date and a comperision word\n",
      "Aritcle 33 has a date and a comperision word\n",
      "Aritcle 36 has a date and a comperision word\n",
      "Aritcle 36 has a date and a comperision word\n",
      "Aritcle 36 has a date and a comperision word\n",
      "Aritcle 37 has a date and a comperision word\n",
      "Aritcle 37 has a date and a comperision word\n",
      "Aritcle 37 has a date and a comperision word\n",
      "Aritcle 64 has a date and a comperision word\n",
      "Aritcle 67 has a date and a comperision word\n",
      "Aritcle 68 has a date and a comperision word\n",
      "Aritcle 68 has a date and a comperision word\n",
      "Aritcle 68 has a date and a comperision word\n",
      "Aritcle 76 has a date and a comperision word\n",
      "Aritcle 76 has a date and a comperision word\n",
      "Aritcle 79 has a date and a comperision word\n",
      "Aritcle 82 has a date and a comperision word\n",
      "Aritcle 82 has a date and a comperision word\n",
      "Aritcle 83 has a date and a comperision word\n",
      "Aritcle 85 has a date and a comperision word\n",
      "Aritcle 85 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 87 has a date and a comperision word\n",
      "Aritcle 91 has a date and a comperision word\n",
      "Aritcle 91 has a date and a comperision word\n",
      "Aritcle 91 has a date and a comperision word\n",
      "Aritcle 91 has a date and a comperision word\n",
      "Aritcle 91 has a date and a comperision word\n",
      "Aritcle 102 has a date and a comperision word\n",
      "Aritcle 102 has a date and a comperision word\n",
      "Aritcle 105 has a date and a comperision word\n",
      "Aritcle 110 has a date and a comperision word\n",
      "Aritcle 111 has a date and a comperision word\n",
      "Aritcle 111 has a date and a comperision word\n",
      "Aritcle 111 has a date and a comperision word\n",
      "Aritcle 113 has a date and a comperision word\n",
      "Aritcle 124 has a date and a comperision word\n",
      "Aritcle 126 has a date and a comperision word\n",
      "Aritcle 126 has a date and a comperision word\n",
      "Aritcle 131 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 132 has a date and a comperision word\n",
      "Aritcle 136 has a date and a comperision word\n",
      "Aritcle 143 has a date and a comperision word\n",
      "Aritcle 143 has a date and a comperision word\n",
      "Aritcle 143 has a date and a comperision word\n",
      "Aritcle 144 has a date and a comperision word\n",
      "Aritcle 150 has a date and a comperision word\n",
      "Aritcle 151 has a date and a comperision word\n",
      "Aritcle 151 has a date and a comperision word\n",
      "Aritcle 151 has a date and a comperision word\n",
      "Aritcle 151 has a date and a comperision word\n",
      "Aritcle 152 has a date and a comperision word\n",
      "Aritcle 155 has a date and a comperision word\n",
      "Aritcle 155 has a date and a comperision word\n",
      "Aritcle 157 has a date and a comperision word\n",
      "Aritcle 157 has a date and a comperision word\n",
      "Aritcle 157 has a date and a comperision word\n",
      "Aritcle 157 has a date and a comperision word\n",
      "Aritcle 157 has a date and a comperision word\n",
      "Aritcle 162 has a date and a comperision word\n",
      "Aritcle 172 has a date and a comperision word\n",
      "Aritcle 172 has a date and a comperision word\n",
      "Aritcle 172 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 173 has a date and a comperision word\n",
      "Aritcle 175 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 184 has a date and a comperision word\n",
      "Aritcle 188 has a date and a comperision word\n",
      "Aritcle 188 has a date and a comperision word\n",
      "Aritcle 188 has a date and a comperision word\n",
      "Aritcle 188 has a date and a comperision word\n",
      "Aritcle 188 has a date and a comperision word\n",
      "Aritcle 194 has a date and a comperision word\n",
      "Aritcle 207 has a date and a comperision word\n",
      "Aritcle 207 has a date and a comperision word\n",
      "Aritcle 207 has a date and a comperision word\n",
      "Aritcle 218 has a date and a comperision word\n",
      "Aritcle 218 has a date and a comperision word\n",
      "Aritcle 222 has a date and a comperision word\n",
      "Aritcle 232 has a date and a comperision word\n",
      "Aritcle 232 has a date and a comperision word\n",
      "Aritcle 232 has a date and a comperision word\n",
      "Aritcle 234 has a date and a comperision word\n",
      "Aritcle 234 has a date and a comperision word\n",
      "Aritcle 234 has a date and a comperision word\n",
      "Aritcle 235 has a date and a comperision word\n",
      "Aritcle 235 has a date and a comperision word\n",
      "Aritcle 235 has a date and a comperision word\n",
      "Aritcle 235 has a date and a comperision word\n",
      "Aritcle 235 has a date and a comperision word\n",
      "Aritcle 236 has a date and a comperision word\n",
      "Aritcle 237 has a date and a comperision word\n",
      "Aritcle 237 has a date and a comperision word\n",
      "Aritcle 237 has a date and a comperision word\n",
      "Aritcle 237 has a date and a comperision word\n",
      "Aritcle 237 has a date and a comperision word\n",
      "Aritcle 253 has a date and a comperision word\n",
      "Aritcle 253 has a date and a comperision word\n",
      "Aritcle 257 has a date and a comperision word\n",
      "Aritcle 258 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 260 has a date and a comperision word\n",
      "Aritcle 263 has a date and a comperision word\n",
      "Aritcle 263 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 266 has a date and a comperision word\n",
      "Aritcle 269 has a date and a comperision word\n",
      "Aritcle 269 has a date and a comperision word\n",
      "Aritcle 271 has a date and a comperision word\n",
      "Aritcle 271 has a date and a comperision word\n",
      "Aritcle 271 has a date and a comperision word\n",
      "Aritcle 271 has a date and a comperision word\n",
      "Aritcle 273 has a date and a comperision word\n",
      "Aritcle 277 has a date and a comperision word\n",
      "Aritcle 277 has a date and a comperision word\n",
      "Aritcle 277 has a date and a comperision word\n",
      "Aritcle 284 has a date and a comperision word\n",
      "Aritcle 284 has a date and a comperision word\n",
      "Aritcle 284 has a date and a comperision word\n",
      "Aritcle 284 has a date and a comperision word\n",
      "Aritcle 284 has a date and a comperision word\n",
      "Aritcle 286 has a date and a comperision word\n",
      "Aritcle 294 has a date and a comperision word\n",
      "Aritcle 294 has a date and a comperision word\n",
      "Aritcle 298 has a date and a comperision word\n",
      "Aritcle 301 has a date and a comperision word\n",
      "Aritcle 301 has a date and a comperision word\n",
      "Aritcle 301 has a date and a comperision word\n",
      "Aritcle 318 has a date and a comperision word\n",
      "Aritcle 318 has a date and a comperision word\n",
      "Aritcle 318 has a date and a comperision word\n",
      "Aritcle 318 has a date and a comperision word\n",
      "Aritcle 319 has a date and a comperision word\n",
      "Aritcle 319 has a date and a comperision word\n",
      "Aritcle 319 has a date and a comperision word\n",
      "Aritcle 319 has a date and a comperision word\n",
      "Aritcle 321 has a date and a comperision word\n",
      "Aritcle 321 has a date and a comperision word\n",
      "Aritcle 321 has a date and a comperision word\n",
      "Aritcle 321 has a date and a comperision word\n",
      "Aritcle 324 has a date and a comperision word\n",
      "Aritcle 324 has a date and a comperision word\n",
      "Aritcle 324 has a date and a comperision word\n",
      "Aritcle 329 has a date and a comperision word\n",
      "Aritcle 329 has a date and a comperision word\n",
      "Aritcle 329 has a date and a comperision word\n",
      "Aritcle 329 has a date and a comperision word\n",
      "Aritcle 333 has a date and a comperision word\n",
      "Aritcle 339 has a date and a comperision word\n",
      "Aritcle 339 has a date and a comperision word\n",
      "Aritcle 342 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 352 has a date and a comperision word\n",
      "Aritcle 364 has a date and a comperision word\n",
      "Aritcle 364 has a date and a comperision word\n",
      "Aritcle 364 has a date and a comperision word\n",
      "Aritcle 367 has a date and a comperision word\n",
      "Aritcle 367 has a date and a comperision word\n",
      "Aritcle 372 has a date and a comperision word\n",
      "Aritcle 372 has a date and a comperision word\n",
      "Aritcle 376 has a date and a comperision word\n",
      "Aritcle 376 has a date and a comperision word\n",
      "Aritcle 376 has a date and a comperision word\n",
      "Aritcle 378 has a date and a comperision word\n",
      "Aritcle 378 has a date and a comperision word\n",
      "Aritcle 378 has a date and a comperision word\n",
      "Aritcle 380 has a date and a comperision word\n",
      "Aritcle 380 has a date and a comperision word\n",
      "Aritcle 381 has a date and a comperision word\n",
      "Aritcle 381 has a date and a comperision word\n",
      "Aritcle 394 has a date and a comperision word\n",
      "Aritcle 394 has a date and a comperision word\n",
      "Aritcle 394 has a date and a comperision word\n",
      "Aritcle 394 has a date and a comperision word\n",
      "Aritcle 394 has a date and a comperision word\n",
      "Aritcle 398 has a date and a comperision word\n",
      "Aritcle 398 has a date and a comperision word\n",
      "Aritcle 398 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 401 has a date and a comperision word\n",
      "Aritcle 402 has a date and a comperision word\n",
      "Aritcle 405 has a date and a comperision word\n",
      "Aritcle 409 has a date and a comperision word\n",
      "Aritcle 414 has a date and a comperision word\n",
      "Aritcle 414 has a date and a comperision word\n",
      "Aritcle 423 has a date and a comperision word\n",
      "Aritcle 427 has a date and a comperision word\n",
      "Aritcle 429 has a date and a comperision word\n",
      "Aritcle 429 has a date and a comperision word\n",
      "Aritcle 429 has a date and a comperision word\n",
      "Aritcle 429 has a date and a comperision word\n",
      "Aritcle 431 has a date and a comperision word\n",
      "Aritcle 440 has a date and a comperision word\n",
      "Aritcle 440 has a date and a comperision word\n",
      "Aritcle 440 has a date and a comperision word\n",
      "Aritcle 446 has a date and a comperision word\n",
      "Aritcle 446 has a date and a comperision word\n",
      "Aritcle 446 has a date and a comperision word\n",
      "Aritcle 446 has a date and a comperision word\n",
      "Aritcle 446 has a date and a comperision word\n",
      "Aritcle 457 has a date and a comperision word\n",
      "Aritcle 457 has a date and a comperision word\n",
      "Aritcle 457 has a date and a comperision word\n",
      "Aritcle 461 has a date and a comperision word\n",
      "Aritcle 472 has a date and a comperision word\n",
      "Aritcle 472 has a date and a comperision word\n",
      "Aritcle 472 has a date and a comperision word\n",
      "Aritcle 472 has a date and a comperision word\n",
      "Aritcle 473 has a date and a comperision word\n",
      "Aritcle 473 has a date and a comperision word\n",
      "Aritcle 477 has a date and a comperision word\n",
      "Aritcle 481 has a date and a comperision word\n",
      "Aritcle 481 has a date and a comperision word\n",
      "Aritcle 481 has a date and a comperision word\n",
      "Aritcle 481 has a date and a comperision word\n",
      "Aritcle 481 has a date and a comperision word\n",
      "Aritcle 483 has a date and a comperision word\n",
      "Aritcle 483 has a date and a comperision word\n",
      "Aritcle 483 has a date and a comperision word\n",
      "Aritcle 500 has a date and a comperision word\n",
      "Aritcle 504 has a date and a comperision word\n",
      "Aritcle 508 has a date and a comperision word\n",
      "Aritcle 508 has a date and a comperision word\n",
      "Aritcle 508 has a date and a comperision word\n",
      "Aritcle 508 has a date and a comperision word\n",
      "Aritcle 512 has a date and a comperision word\n",
      "Aritcle 512 has a date and a comperision word\n",
      "Aritcle 512 has a date and a comperision word\n",
      "Aritcle 512 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 527 has a date and a comperision word\n",
      "Aritcle 528 has a date and a comperision word\n",
      "Aritcle 528 has a date and a comperision word\n",
      "Aritcle 532 has a date and a comperision word\n",
      "Aritcle 532 has a date and a comperision word\n",
      "Aritcle 532 has a date and a comperision word\n",
      "Aritcle 532 has a date and a comperision word\n",
      "Aritcle 535 has a date and a comperision word\n",
      "Aritcle 541 has a date and a comperision word\n",
      "Aritcle 541 has a date and a comperision word\n",
      "Aritcle 545 has a date and a comperision word\n",
      "Aritcle 545 has a date and a comperision word\n",
      "Aritcle 545 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 556 has a date and a comperision word\n",
      "Aritcle 565 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n",
      "Aritcle 571 has a date and a comperision word\n"
     ]
    }
   ],
   "source": [
    "indices = nlp_filter('biomass', 'query', df, 'Historical', 'Abstract', 10, 'word_mover_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 34,\n",
       " 35,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 103,\n",
       " 104,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 125,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 146,\n",
       " 148,\n",
       " 149,\n",
       " 153,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 174,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 216,\n",
       " 217,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 233,\n",
       " 238,\n",
       " 239,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 252,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 259,\n",
       " 261,\n",
       " 262,\n",
       " 265,\n",
       " 267,\n",
       " 268,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 299,\n",
       " 300,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 320,\n",
       " 323,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 330,\n",
       " 332,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 340,\n",
       " 341,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 362,\n",
       " 363,\n",
       " 365,\n",
       " 366,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 377,\n",
       " 379,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 399,\n",
       " 400,\n",
       " 403,\n",
       " 404,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 428,\n",
       " 430,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 458,\n",
       " 459,\n",
       " 462,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 482,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 501,\n",
       " 502,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 529,\n",
       " 531,\n",
       " 533,\n",
       " 534,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Filter Type 'Regional':\n",
    "\n",
    "If user want to filter out all the articles that have name of a Geo Political Entity in them he/she can type 'Regional' in filter_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritcle 1 has a Geopolitical Entity in it\n",
      "Aritcle 2 has a Geopolitical Entity in it\n",
      "Aritcle 3 has a Geopolitical Entity in it\n",
      "Aritcle 6 has a Geopolitical Entity in it\n",
      "Aritcle 9 has a Geopolitical Entity in it\n",
      "Aritcle 13 has a Geopolitical Entity in it\n",
      "Aritcle 14 has a Geopolitical Entity in it\n",
      "Aritcle 16 has a Geopolitical Entity in it\n",
      "Aritcle 19 has a Geopolitical Entity in it\n",
      "Aritcle 20 has a Geopolitical Entity in it\n",
      "Aritcle 33 has a Geopolitical Entity in it\n",
      "Aritcle 35 has a Geopolitical Entity in it\n",
      "Aritcle 37 has a Geopolitical Entity in it\n",
      "Aritcle 42 has a Geopolitical Entity in it\n",
      "Aritcle 46 has a Geopolitical Entity in it\n",
      "Aritcle 50 has a Geopolitical Entity in it\n",
      "Aritcle 53 has a Geopolitical Entity in it\n",
      "Aritcle 60 has a Geopolitical Entity in it\n",
      "Aritcle 64 has a Geopolitical Entity in it\n",
      "Aritcle 74 has a Geopolitical Entity in it\n",
      "Aritcle 76 has a Geopolitical Entity in it\n",
      "Aritcle 79 has a Geopolitical Entity in it\n",
      "Aritcle 82 has a Geopolitical Entity in it\n",
      "Aritcle 84 has a Geopolitical Entity in it\n",
      "Aritcle 86 has a Geopolitical Entity in it\n",
      "Aritcle 88 has a Geopolitical Entity in it\n",
      "Aritcle 89 has a Geopolitical Entity in it\n",
      "Aritcle 93 has a Geopolitical Entity in it\n",
      "Aritcle 94 has a Geopolitical Entity in it\n",
      "Aritcle 100 has a Geopolitical Entity in it\n",
      "Aritcle 101 has a Geopolitical Entity in it\n",
      "Aritcle 105 has a Geopolitical Entity in it\n",
      "Aritcle 107 has a Geopolitical Entity in it\n",
      "Aritcle 109 has a Geopolitical Entity in it\n",
      "Aritcle 110 has a Geopolitical Entity in it\n",
      "Aritcle 112 has a Geopolitical Entity in it\n",
      "Aritcle 115 has a Geopolitical Entity in it\n",
      "Aritcle 116 has a Geopolitical Entity in it\n",
      "Aritcle 118 has a Geopolitical Entity in it\n",
      "Aritcle 119 has a Geopolitical Entity in it\n",
      "Aritcle 122 has a Geopolitical Entity in it\n",
      "Aritcle 124 has a Geopolitical Entity in it\n",
      "Aritcle 125 has a Geopolitical Entity in it\n",
      "Aritcle 127 has a Geopolitical Entity in it\n",
      "Aritcle 129 has a Geopolitical Entity in it\n",
      "Aritcle 131 has a Geopolitical Entity in it\n",
      "Aritcle 134 has a Geopolitical Entity in it\n",
      "Aritcle 135 has a Geopolitical Entity in it\n",
      "Aritcle 136 has a Geopolitical Entity in it\n",
      "Aritcle 137 has a Geopolitical Entity in it\n",
      "Aritcle 138 has a Geopolitical Entity in it\n",
      "Aritcle 139 has a Geopolitical Entity in it\n",
      "Aritcle 140 has a Geopolitical Entity in it\n",
      "Aritcle 142 has a Geopolitical Entity in it\n",
      "Aritcle 143 has a Geopolitical Entity in it\n",
      "Aritcle 144 has a Geopolitical Entity in it\n",
      "Aritcle 145 has a Geopolitical Entity in it\n",
      "Aritcle 146 has a Geopolitical Entity in it\n",
      "Aritcle 148 has a Geopolitical Entity in it\n",
      "Aritcle 149 has a Geopolitical Entity in it\n",
      "Aritcle 151 has a Geopolitical Entity in it\n",
      "Aritcle 152 has a Geopolitical Entity in it\n",
      "Aritcle 154 has a Geopolitical Entity in it\n",
      "Aritcle 155 has a Geopolitical Entity in it\n",
      "Aritcle 156 has a Geopolitical Entity in it\n",
      "Aritcle 157 has a Geopolitical Entity in it\n",
      "Aritcle 158 has a Geopolitical Entity in it\n",
      "Aritcle 165 has a Geopolitical Entity in it\n",
      "Aritcle 173 has a Geopolitical Entity in it\n",
      "Aritcle 174 has a Geopolitical Entity in it\n",
      "Aritcle 184 has a Geopolitical Entity in it\n",
      "Aritcle 185 has a Geopolitical Entity in it\n",
      "Aritcle 188 has a Geopolitical Entity in it\n",
      "Aritcle 189 has a Geopolitical Entity in it\n",
      "Aritcle 193 has a Geopolitical Entity in it\n",
      "Aritcle 194 has a Geopolitical Entity in it\n",
      "Aritcle 201 has a Geopolitical Entity in it\n",
      "Aritcle 208 has a Geopolitical Entity in it\n",
      "Aritcle 211 has a Geopolitical Entity in it\n",
      "Aritcle 218 has a Geopolitical Entity in it\n",
      "Aritcle 225 has a Geopolitical Entity in it\n",
      "Aritcle 227 has a Geopolitical Entity in it\n",
      "Aritcle 229 has a Geopolitical Entity in it\n",
      "Aritcle 232 has a Geopolitical Entity in it\n",
      "Aritcle 236 has a Geopolitical Entity in it\n",
      "Aritcle 237 has a Geopolitical Entity in it\n",
      "Aritcle 239 has a Geopolitical Entity in it\n",
      "Aritcle 240 has a Geopolitical Entity in it\n",
      "Aritcle 244 has a Geopolitical Entity in it\n",
      "Aritcle 247 has a Geopolitical Entity in it\n",
      "Aritcle 251 has a Geopolitical Entity in it\n",
      "Aritcle 252 has a Geopolitical Entity in it\n",
      "Aritcle 254 has a Geopolitical Entity in it\n",
      "Aritcle 257 has a Geopolitical Entity in it\n",
      "Aritcle 258 has a Geopolitical Entity in it\n",
      "Aritcle 260 has a Geopolitical Entity in it\n",
      "Aritcle 263 has a Geopolitical Entity in it\n",
      "Aritcle 267 has a Geopolitical Entity in it\n",
      "Aritcle 270 has a Geopolitical Entity in it\n",
      "Aritcle 271 has a Geopolitical Entity in it\n",
      "Aritcle 272 has a Geopolitical Entity in it\n",
      "Aritcle 284 has a Geopolitical Entity in it\n",
      "Aritcle 292 has a Geopolitical Entity in it\n",
      "Aritcle 293 has a Geopolitical Entity in it\n",
      "Aritcle 295 has a Geopolitical Entity in it\n",
      "Aritcle 298 has a Geopolitical Entity in it\n",
      "Aritcle 299 has a Geopolitical Entity in it\n",
      "Aritcle 302 has a Geopolitical Entity in it\n",
      "Aritcle 305 has a Geopolitical Entity in it\n",
      "Aritcle 308 has a Geopolitical Entity in it\n",
      "Aritcle 309 has a Geopolitical Entity in it\n",
      "Aritcle 312 has a Geopolitical Entity in it\n",
      "Aritcle 314 has a Geopolitical Entity in it\n",
      "Aritcle 319 has a Geopolitical Entity in it\n",
      "Aritcle 321 has a Geopolitical Entity in it\n",
      "Aritcle 323 has a Geopolitical Entity in it\n",
      "Aritcle 331 has a Geopolitical Entity in it\n",
      "Aritcle 332 has a Geopolitical Entity in it\n",
      "Aritcle 333 has a Geopolitical Entity in it\n",
      "Aritcle 334 has a Geopolitical Entity in it\n",
      "Aritcle 338 has a Geopolitical Entity in it\n",
      "Aritcle 339 has a Geopolitical Entity in it\n",
      "Aritcle 341 has a Geopolitical Entity in it\n",
      "Aritcle 344 has a Geopolitical Entity in it\n",
      "Aritcle 346 has a Geopolitical Entity in it\n",
      "Aritcle 347 has a Geopolitical Entity in it\n",
      "Aritcle 361 has a Geopolitical Entity in it\n",
      "Aritcle 364 has a Geopolitical Entity in it\n",
      "Aritcle 365 has a Geopolitical Entity in it\n",
      "Aritcle 373 has a Geopolitical Entity in it\n",
      "Aritcle 380 has a Geopolitical Entity in it\n",
      "Aritcle 384 has a Geopolitical Entity in it\n",
      "Aritcle 385 has a Geopolitical Entity in it\n",
      "Aritcle 388 has a Geopolitical Entity in it\n",
      "Aritcle 393 has a Geopolitical Entity in it\n",
      "Aritcle 394 has a Geopolitical Entity in it\n",
      "Aritcle 395 has a Geopolitical Entity in it\n",
      "Aritcle 409 has a Geopolitical Entity in it\n",
      "Aritcle 412 has a Geopolitical Entity in it\n",
      "Aritcle 422 has a Geopolitical Entity in it\n",
      "Aritcle 426 has a Geopolitical Entity in it\n",
      "Aritcle 427 has a Geopolitical Entity in it\n",
      "Aritcle 428 has a Geopolitical Entity in it\n",
      "Aritcle 431 has a Geopolitical Entity in it\n",
      "Aritcle 434 has a Geopolitical Entity in it\n",
      "Aritcle 435 has a Geopolitical Entity in it\n",
      "Aritcle 441 has a Geopolitical Entity in it\n",
      "Aritcle 442 has a Geopolitical Entity in it\n",
      "Aritcle 445 has a Geopolitical Entity in it\n",
      "Aritcle 447 has a Geopolitical Entity in it\n",
      "Aritcle 450 has a Geopolitical Entity in it\n",
      "Aritcle 454 has a Geopolitical Entity in it\n",
      "Aritcle 456 has a Geopolitical Entity in it\n",
      "Aritcle 458 has a Geopolitical Entity in it\n",
      "Aritcle 460 has a Geopolitical Entity in it\n",
      "Aritcle 462 has a Geopolitical Entity in it\n",
      "Aritcle 464 has a Geopolitical Entity in it\n",
      "Aritcle 469 has a Geopolitical Entity in it\n",
      "Aritcle 482 has a Geopolitical Entity in it\n",
      "Aritcle 483 has a Geopolitical Entity in it\n",
      "Aritcle 486 has a Geopolitical Entity in it\n",
      "Aritcle 495 has a Geopolitical Entity in it\n",
      "Aritcle 516 has a Geopolitical Entity in it\n",
      "Aritcle 518 has a Geopolitical Entity in it\n",
      "Aritcle 532 has a Geopolitical Entity in it\n",
      "Aritcle 536 has a Geopolitical Entity in it\n",
      "Aritcle 539 has a Geopolitical Entity in it\n",
      "Aritcle 542 has a Geopolitical Entity in it\n",
      "Aritcle 543 has a Geopolitical Entity in it\n",
      "Aritcle 545 has a Geopolitical Entity in it\n",
      "Aritcle 546 has a Geopolitical Entity in it\n",
      "Aritcle 547 has a Geopolitical Entity in it\n",
      "Aritcle 550 has a Geopolitical Entity in it\n",
      "Aritcle 551 has a Geopolitical Entity in it\n",
      "Aritcle 553 has a Geopolitical Entity in it\n",
      "Aritcle 556 has a Geopolitical Entity in it\n",
      "Aritcle 563 has a Geopolitical Entity in it\n",
      "Aritcle 565 has a Geopolitical Entity in it\n",
      "Aritcle 571 has a Geopolitical Entity in it\n",
      "Aritcle 578 has a Geopolitical Entity in it\n",
      "Aritcle 585 has a Geopolitical Entity in it\n"
     ]
    }
   ],
   "source": [
    "indices = nlp_filter('biomass', 'query', df, 'Regional', 'Abstract', 10, 'word_mover_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 17,\n",
       " 18,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 52,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 75,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 83,\n",
       " 85,\n",
       " 87,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 106,\n",
       " 108,\n",
       " 111,\n",
       " 113,\n",
       " 114,\n",
       " 117,\n",
       " 120,\n",
       " 121,\n",
       " 123,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 133,\n",
       " 141,\n",
       " 147,\n",
       " 150,\n",
       " 153,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 186,\n",
       " 187,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 209,\n",
       " 210,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 226,\n",
       " 228,\n",
       " 230,\n",
       " 231,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 238,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 245,\n",
       " 246,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 253,\n",
       " 255,\n",
       " 256,\n",
       " 259,\n",
       " 261,\n",
       " 262,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 268,\n",
       " 269,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 294,\n",
       " 296,\n",
       " 297,\n",
       " 300,\n",
       " 301,\n",
       " 303,\n",
       " 304,\n",
       " 306,\n",
       " 307,\n",
       " 310,\n",
       " 311,\n",
       " 313,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 320,\n",
       " 322,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 340,\n",
       " 342,\n",
       " 343,\n",
       " 345,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 362,\n",
       " 363,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 386,\n",
       " 387,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 410,\n",
       " 411,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 429,\n",
       " 430,\n",
       " 432,\n",
       " 433,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 443,\n",
       " 444,\n",
       " 446,\n",
       " 448,\n",
       " 449,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 455,\n",
       " 457,\n",
       " 459,\n",
       " 461,\n",
       " 463,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 484,\n",
       " 485,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 517,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 537,\n",
       " 538,\n",
       " 540,\n",
       " 541,\n",
       " 544,\n",
       " 548,\n",
       " 549,\n",
       " 552,\n",
       " 554,\n",
       " 555,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 564,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 586,\n",
       " 587,\n",
       " 588]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - col_name 'Abstract':\n",
    "\n",
    "If user select 'Abstract' in col_name then both tfidf and word_mover_distance methods will perform their calculations on Abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('genetic engineering', 'query', df, 'Keywords', 'Abstract', 10, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 11: Fundamentals of Biochemical Reacti...</td>\n",
       "      <td>Biochemical reaction engineering is a branch o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Genetic engineering of wood</td>\n",
       "      <td>The technology of genetic engineering provides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Biodiesel production from genetically engineer...</td>\n",
       "      <td>Current biomass sources for energy production ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Chapter 1: Genetic Engineered Organisms (Plant...</td>\n",
       "      <td>Genetically modified organism (GMO) is one who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Genetic Manipulation of Non-Classic Oilseed Pl...</td>\n",
       "      <td>Global demand for vegetable oil is anticipated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Chapter 16: Engineering Lessons—Using Engineer...</td>\n",
       "      <td>Engineering plays a critical role in most aspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Cellulolytic and xylanolytic enzymes of thermo...</td>\n",
       "      <td>Thermophilic microorganisms are ubiquitous in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Cellulolytic and xylanolytic enzymes of thermo...</td>\n",
       "      <td>Thermophilic microorganisms are ubiquitous in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Programming Cell-Cell Interactions through Non...</td>\n",
       "      <td>The ability to direct targeted intercellular i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Chapter 2: Metabolic Engineering and Genetic M...</td>\n",
       "      <td>Agricultural biomass offers one of the best pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Chapter 11: Fundamentals of Biochemical Reacti...   \n",
       "1                        Genetic engineering of wood   \n",
       "2  Biodiesel production from genetically engineer...   \n",
       "3  Chapter 1: Genetic Engineered Organisms (Plant...   \n",
       "4  Genetic Manipulation of Non-Classic Oilseed Pl...   \n",
       "5  Chapter 16: Engineering Lessons—Using Engineer...   \n",
       "6  Cellulolytic and xylanolytic enzymes of thermo...   \n",
       "7  Cellulolytic and xylanolytic enzymes of thermo...   \n",
       "8  Programming Cell-Cell Interactions through Non...   \n",
       "9  Chapter 2: Metabolic Engineering and Genetic M...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Biochemical reaction engineering is a branch o...  \n",
       "1  The technology of genetic engineering provides...  \n",
       "2  Current biomass sources for energy production ...  \n",
       "3  Genetically modified organism (GMO) is one who...  \n",
       "4  Global demand for vegetable oil is anticipated...  \n",
       "5  Engineering plays a critical role in most aspe...  \n",
       "6  Thermophilic microorganisms are ubiquitous in ...  \n",
       "7  Thermophilic microorganisms are ubiquitous in ...  \n",
       "8  The ability to direct targeted intercellular i...  \n",
       "9  Agricultural biomass offers one of the best pl...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - col_name 'Title':\n",
    "\n",
    "If user select 'Title' in col_name then both tfidf and word_mover_distance methods will perform their calculations on Title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('genetic engineering', 'query', df, 'Keywords', 'Title', 10, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Genetic engineering of wood</td>\n",
       "      <td>The technology of genetic engineering provides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Genetic engineering in biomimetic composites</td>\n",
       "      <td>Composites represent a class of materials with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Biochemical engineering</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Biochemical engineering</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Biochemical engineering</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Advances in genetic engineering of marine algae</td>\n",
       "      <td>Algae are a component of bait sources for anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Biochemical engineering</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Genetic engineering of E. coli SE5000 and its ...</td>\n",
       "      <td>A genetically engineered Escherichia coli SE50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.58: Biorefinery Engineering</td>\n",
       "      <td>Biorefinery that utilizes renewables for produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Engineering aspects of ensiling</td>\n",
       "      <td>Ensiling is a preservation method for moist fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Genetic engineering of wood   \n",
       "1       Genetic engineering in biomimetic composites   \n",
       "2                            Biochemical engineering   \n",
       "3                            Biochemical engineering   \n",
       "4                            Biochemical engineering   \n",
       "5    Advances in genetic engineering of marine algae   \n",
       "6                            Biochemical engineering   \n",
       "7  Genetic engineering of E. coli SE5000 and its ...   \n",
       "8                      2.58: Biorefinery Engineering   \n",
       "9                    Engineering aspects of ensiling   \n",
       "\n",
       "                                            Abstract  \n",
       "0  The technology of genetic engineering provides...  \n",
       "1  Composites represent a class of materials with...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "5  Algae are a component of bait sources for anim...  \n",
       "6                                                     \n",
       "7  A genetically engineered Escherichia coli SE50...  \n",
       "8  Biorefinery that utilizes renewables for produ...  \n",
       "9  Ensiling is a preservation method for moist fo...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - col_name 'Title':\n",
    "\n",
    "If user select 'Abstract+Title' in col_name then tfidf will calculate relevence on both Abstracts and Titles while word_mover_distance will only calculate the relevence on Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('genetic engineering', 'query', df, 'Keywords', 'Abstract+Title', 10, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 11: Fundamentals of Biochemical Reacti...</td>\n",
       "      <td>Biochemical reaction engineering is a branch o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Genetic engineering of wood</td>\n",
       "      <td>The technology of genetic engineering provides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Chapter 16: Engineering Lessons—Using Engineer...</td>\n",
       "      <td>Engineering plays a critical role in most aspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Genetic engineering in biomimetic composites</td>\n",
       "      <td>Composites represent a class of materials with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Chapter 1: Genetic Engineered Organisms (Plant...</td>\n",
       "      <td>Genetically modified organism (GMO) is one who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Chemistry and engineering of the production pr...</td>\n",
       "      <td>The present paper discusses the evolution of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Chapter 2: Metabolic Engineering and Genetic M...</td>\n",
       "      <td>Agricultural biomass offers one of the best pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Lignin genetic engineering for improvement of ...</td>\n",
       "      <td>Lignin, a complex racemic phenolic heteropolym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Lignin genetic engineering for improvement of ...</td>\n",
       "      <td>Lignin, a complex racemic phenolic heteropolym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Chapter 14: Genetic Engineering Applications t...</td>\n",
       "      <td>Cellulase production with superior expertise i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Chapter 11: Fundamentals of Biochemical Reacti...   \n",
       "1                        Genetic engineering of wood   \n",
       "2  Chapter 16: Engineering Lessons—Using Engineer...   \n",
       "3       Genetic engineering in biomimetic composites   \n",
       "4  Chapter 1: Genetic Engineered Organisms (Plant...   \n",
       "5  Chemistry and engineering of the production pr...   \n",
       "6  Chapter 2: Metabolic Engineering and Genetic M...   \n",
       "7  Lignin genetic engineering for improvement of ...   \n",
       "8  Lignin genetic engineering for improvement of ...   \n",
       "9  Chapter 14: Genetic Engineering Applications t...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Biochemical reaction engineering is a branch o...  \n",
       "1  The technology of genetic engineering provides...  \n",
       "2  Engineering plays a critical role in most aspe...  \n",
       "3  Composites represent a class of materials with...  \n",
       "4  Genetically modified organism (GMO) is one who...  \n",
       "5  The present paper discusses the evolution of t...  \n",
       "6  Agricultural biomass offers one of the best pl...  \n",
       "7  Lignin, a complex racemic phenolic heteropolym...  \n",
       "8  Lignin, a complex racemic phenolic heteropolym...  \n",
       "9  Cellulase production with superior expertise i...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - similarity_method 'tfidf':\n",
    "\n",
    "If the user select similarity_method 'tfidf' the function will return the list of indices of the k most relevent articles to the query based on word frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('biomass', 'query', df, 'Keywords', 'Abstract', 10, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 3: Biomass Torrefaction Process</td>\n",
       "      <td>This chapter presents an overview of the torre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Phosphorus recovery from the biomass ash: A re...</td>\n",
       "      <td>Biomass ash, generated during the thermal chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Phosphorus recovery from the biomass ash: A re...</td>\n",
       "      <td>Biomass ash, generated during the thermal chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Chapter 3: Biomass Characteristics</td>\n",
       "      <td>The characteristics of biomass greatly influen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hydrothermal conversion of biomass to fuels an...</td>\n",
       "      <td>Available biomass, preferentially residues, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>A review on exergy analysis of biomass based f...</td>\n",
       "      <td>Renewable energy sources can be a good substit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Biomass supply chain optimisation via novel Bi...</td>\n",
       "      <td>Negative environment impacts and security issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The co-combustion of hard coal with raw and to...</td>\n",
       "      <td>The co-combustion of raw and torrefied biomass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Potential of cofiring with biomass in Italy</td>\n",
       "      <td>Biomass is considered a potential fuel and a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4: Biomass feedstock for IGCC systems</td>\n",
       "      <td>Biomass gasification integrated with a gas tur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0            Chapter 3: Biomass Torrefaction Process   \n",
       "1  Phosphorus recovery from the biomass ash: A re...   \n",
       "2  Phosphorus recovery from the biomass ash: A re...   \n",
       "3                 Chapter 3: Biomass Characteristics   \n",
       "4  Hydrothermal conversion of biomass to fuels an...   \n",
       "5  A review on exergy analysis of biomass based f...   \n",
       "6  Biomass supply chain optimisation via novel Bi...   \n",
       "7  The co-combustion of hard coal with raw and to...   \n",
       "8        Potential of cofiring with biomass in Italy   \n",
       "9              4: Biomass feedstock for IGCC systems   \n",
       "\n",
       "                                            Abstract  \n",
       "0  This chapter presents an overview of the torre...  \n",
       "1  Biomass ash, generated during the thermal chem...  \n",
       "2  Biomass ash, generated during the thermal chem...  \n",
       "3  The characteristics of biomass greatly influen...  \n",
       "4  Available biomass, preferentially residues, ca...  \n",
       "5  Renewable energy sources can be a good substit...  \n",
       "6  Negative environment impacts and security issu...  \n",
       "7  The co-combustion of raw and torrefied biomass...  \n",
       "8  Biomass is considered a potential fuel and a r...  \n",
       "9  Biomass gasification integrated with a gas tur...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - similarity_method 'word_mover_distance':\n",
    "If the user select similarity_method 'word_mover_distance' the function will return the list of indices of the k most relevent articles to the query based on word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nlp_filter('biomass', 'query', df, 'Keywords', 'Abstract', 10, 'word_mover_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 3: Biomass Torrefaction Process</td>\n",
       "      <td>This chapter presents an overview of the torre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Phosphorus recovery from the biomass ash: A re...</td>\n",
       "      <td>Biomass ash, generated during the thermal chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Phosphorus recovery from the biomass ash: A re...</td>\n",
       "      <td>Biomass ash, generated during the thermal chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A review on exergy analysis of biomass based f...</td>\n",
       "      <td>Renewable energy sources can be a good substit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4: Biomass feedstock for IGCC systems</td>\n",
       "      <td>Biomass gasification integrated with a gas tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The co-combustion of hard coal with raw and to...</td>\n",
       "      <td>The co-combustion of raw and torrefied biomass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Hydrothermal conversion of biomass to fuels an...</td>\n",
       "      <td>Available biomass, preferentially residues, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Chapter 3: Biomass Characteristics</td>\n",
       "      <td>The characteristics of biomass greatly influen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>An Assessment of the Effects of Biomass Proces...</td>\n",
       "      <td>Biomass can be cofired with coal in different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Potential of cofiring with biomass in Italy</td>\n",
       "      <td>Biomass is considered a potential fuel and a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0            Chapter 3: Biomass Torrefaction Process   \n",
       "1  Phosphorus recovery from the biomass ash: A re...   \n",
       "2  Phosphorus recovery from the biomass ash: A re...   \n",
       "3  A review on exergy analysis of biomass based f...   \n",
       "4              4: Biomass feedstock for IGCC systems   \n",
       "5  The co-combustion of hard coal with raw and to...   \n",
       "6  Hydrothermal conversion of biomass to fuels an...   \n",
       "7                 Chapter 3: Biomass Characteristics   \n",
       "8  An Assessment of the Effects of Biomass Proces...   \n",
       "9        Potential of cofiring with biomass in Italy   \n",
       "\n",
       "                                            Abstract  \n",
       "0  This chapter presents an overview of the torre...  \n",
       "1  Biomass ash, generated during the thermal chem...  \n",
       "2  Biomass ash, generated during the thermal chem...  \n",
       "3  Renewable energy sources can be a good substit...  \n",
       "4  Biomass gasification integrated with a gas tur...  \n",
       "5  The co-combustion of raw and torrefied biomass...  \n",
       "6  Available biomass, preferentially residues, ca...  \n",
       "7  The characteristics of biomass greatly influen...  \n",
       "8  Biomass can be cofired with coal in different ...  \n",
       "9  Biomass is considered a potential fuel and a r...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "abstract = []\n",
    "for i in indices:\n",
    "    title.append(df.loc[i, 'Title'])\n",
    "    abstract.append(df.loc[i, 'Abstract'])\n",
    "data = pd.DataFrame()\n",
    "data['Title'] = title\n",
    "data['Abstract'] = abstract\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
